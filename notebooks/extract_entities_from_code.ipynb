{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract python codes from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base.py',\n",
       " 'completion.py',\n",
       " 'config.yaml',\n",
       " 'constants.py',\n",
       " 'main.py',\n",
       " 'moderation.py',\n",
       " 'utils.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_dir = '../../gpt-discord-bot/src/'\n",
    "file_list = os.listdir(file_dir); file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../gpt-discord-bot/src/base.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'from dataclasses import dataclass\\nfrom typing import Optional, List\\n\\nSEPARATOR_TOKEN = \"<|endoftext|>\"\\n\\n\\n@dataclass(frozen=True)\\nclass Message:\\n    user: str\\n    text: Optional[str] = None\\n\\n    def render(self):\\n        result = self.user + \":\"\\n        if self.text is not None:\\n            result += \" \" + self.text\\n        return result\\n\\n\\n@dataclass\\nclass Conversation:\\n    messages: List[Message]\\n\\n    def prepend(self, message: Message):\\n        self.messages.insert(0, message)\\n        return self\\n\\n    def render(self):\\n        return f\"\\\\n{SEPARATOR_TOKEN}\".join(\\n            [message.render() for message in self.messages]\\n        )\\n\\n\\n@dataclass(frozen=True)\\nclass Config:\\n    name: str\\n    instructions: str\\n    example_conversations: List[Conversation]\\n\\n\\n@dataclass(frozen=True)\\nclass Prompt:\\n    header: Message\\n    examples: List[Conversation]\\n    convo: Conversation\\n\\n    def render(self):\\n        return f\"\\\\n{SEPARATOR_TOKEN}\".join(\\n            [self.header.render()]\\n            + [Message(\"System\", \"Example conversations:\").render()]\\n            + [conversation.render() for conversation in self.examples]\\n            + [Message(\"System\", \"Current conversation:\").render()]\\n            + [self.convo.render()],\\n        )\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = os.path.join(file_dir, file_list[0]); fname\n",
    "f = open(fname, \"r\")\n",
    "code = f.read()\n",
    "code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add prompt to code to extract `class` and `def`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_postfix = \"\"\" \n",
    "###\n",
    "Please make a table summarizing the type of function in the code above:\n",
    "|type|name|\n",
    "|class|Message|\n",
    "|def| render|\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from dataclasses import dataclass\\nfrom typing import Optional, List\\n\\nSEPARATOR_TOKEN = \"<|endoftext|>\"\\n\\n\\n@dataclass(frozen=True)\\nclass Message:\\n    user: str\\n    text: Optional[str] = None\\n\\n    def render(self):\\n        result = self.user + \":\"\\n        if self.text is not None:\\n            result += \" \" + self.text\\n        return result\\n\\n\\n@dataclass\\nclass Conversation:\\n    messages: List[Message]\\n\\n    def prepend(self, message: Message):\\n        self.messages.insert(0, message)\\n        return self\\n\\n    def render(self):\\n        return f\"\\\\n{SEPARATOR_TOKEN}\".join(\\n            [message.render() for message in self.messages]\\n        )\\n\\n\\n@dataclass(frozen=True)\\nclass Config:\\n    name: str\\n    instructions: str\\n    example_conversations: List[Conversation]\\n\\n\\n@dataclass(frozen=True)\\nclass Prompt:\\n    header: Message\\n    examples: List[Conversation]\\n    convo: Conversation\\n\\n    def render(self):\\n        return f\"\\\\n{SEPARATOR_TOKEN}\".join(\\n            [self.header.render()]\\n            + [Message(\"System\", \"Example conversations:\").render()]\\n            + [conversation.render() for conversation in self.examples]\\n            + [Message(\"System\", \"Current conversation:\").render()]\\n            + [self.convo.render()],\\n        )\\n \\n###\\nPlease make a table summarizing the type of function in the code above:\\n|type|name|\\n|class|Message|\\n|def| render|\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = code +  prompt_postfix\n",
    "prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request a response from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://tutorial-openai-01-2023.openai.azure.com/\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_api(engine, prompt, temperature, max_tokens, top_p, frequency_penalty, presence_penalty, best_of, stop):\n",
    "  response = openai.Completion.create(\n",
    "    engine=engine,\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=top_p,\n",
    "    frequency_penalty=frequency_penalty, \n",
    "    presence_penalty=presence_penalty,\n",
    "    best_of=best_of,\n",
    "    stop=stop)\n",
    "  return(response)\n",
    "\n",
    "def print_response(response):\n",
    "  response_text = response['choices'][0]['text']\n",
    "  return response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "###\n",
      "Please make a table summarizing the type of function in the code above:\n",
      "|type|name|\n",
      "|class|Message|\n",
      "|def| render|\n",
      "\n",
      "|dataclass|Conversation|\n",
      "|dataclass|Config|\n",
      "|dataclass|Prompt|\n",
      "|def|prepend|\n",
      "|def|render|\n"
     ]
    }
   ],
   "source": [
    "engine=\"text-davinci-003\"\n",
    "prompt=prompt\n",
    "temperature=0 # [0, 1]\n",
    "max_tokens=100\n",
    "top_p=1\n",
    "frequency_penalty=0 # [0, 2]\n",
    "presence_penalty=0 # [0, 2]\n",
    "best_of=1\n",
    "stop=[\"###\"]\n",
    "\n",
    "response = prompt_api(engine, prompt, temperature, max_tokens, top_p, frequency_penalty, presence_penalty, best_of, stop)\n",
    "print(prompt_postfix)\n",
    "response_text = print_response(response); print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "###\n",
      "Please make a table summarizing the type of function in the code above:\n",
      "|type|name|\n",
      "|class|Message|\n",
      "|def| render|\n",
      "|dataclass|Conversation|\n",
      "|dataclass|Config|\n",
      "|dataclass|Prompt|\n",
      "|def|prepend|\n",
      "|def|render|\n"
     ]
    }
   ],
   "source": [
    "output = prompt_postfix + response_text\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output/extract_entities/base.py.output'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file_dir = \"../output/extract_entities/\"\n",
    "fname = os.path.join(output_file_dir, file_list[0] + '.output'); fname\n",
    "output_file = open(fname, \"w\")\n",
    "output_file.write(output)\n",
    "output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
